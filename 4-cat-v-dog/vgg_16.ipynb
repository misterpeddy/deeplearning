{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_16.ipybn",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSSucAgj0Lve",
        "colab_type": "code",
        "outputId": "6a35149d-ef1a-43fa-9ba2-4274dcce0a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYJqJ9en3Y67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip the complete dogs-vs-cats dataset\n",
        "\n",
        "%env DIR=cats_and_dogs\n",
        "\n",
        "! curl -o dogs-vs-cats.zip https://storage.googleapis.com/peddy-ai-dl-data/deeplearning-repo/dogs-vs-cats.zip\n",
        "\n",
        "! unzip -o dogs-vs-cats.zip -d $DIR\n",
        "! mkdir $DIR/original_data\n",
        "! unzip -o $DIR/test1.zip -d $DIR/original_data\n",
        "! unzip -o $DIR/train.zip -d $DIR/original_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GApqrSWm3ZAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create train/validation/test datasets from original data\n",
        "import os, shutil\n",
        "\n",
        "USE_DATA_AUGMENTATION = True\n",
        "\n",
        "base_dir = os.path.join(os.getcwd(), 'cats_and_dogs')\n",
        "original_dataset_dir = os.path.join(base_dir, 'original_data', 'train')\n",
        "\n",
        "data_segment_names = ['train', 'validation', 'test']\n",
        "labels = ['cat', 'dog']\n",
        "\n",
        "data_segments = {\n",
        "\tdata_segment_names[0]: (0, 1000),\n",
        "\tdata_segment_names[1]: (1000, 1500),\n",
        "\tdata_segment_names[2]: (1500, 2000)\n",
        "}\n",
        "\n",
        "def mkdir(dir):\n",
        "\ttry:\n",
        "\t\tos.mkdir(dir)\n",
        "\texcept OSError:\n",
        "\t\tprint('{} not created - alread exists'.format(dir), dir)\n",
        "\n",
        "def prepare_data():\n",
        "\t# Make data segments directories\n",
        "\tfor segment in data_segment_names:\n",
        "\t\tsegment_dir = os.path.join(base_dir, segment)\n",
        "\t\tmkdir(segment_dir)\n",
        "\t\t# Make label directories for each data segment\n",
        "\t\tfor label in labels:\n",
        "\t\t\tlabel_segment_dir = os.path.join(segment_dir, label + 's')\n",
        "\t\t\tmkdir(label_segment_dir)\n",
        "\t\t\t# Copy data over for each data segment-label pair\n",
        "\t\t\tfnames = [(label+'.{}.jpg').format(i) for i in range(data_segments[segment][0], data_segments[segment][1])]\n",
        "\t\t\tfor fname in fnames:\n",
        "\t\t\t\tsrc = os.path.join(original_dataset_dir, fname)\n",
        "\t\t\t\tdst = os.path.join(label_segment_dir, fname)\n",
        "\t\t\t\tshutil.copyfile(src, dst)\n",
        "\n",
        "prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOmYDnry2icA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import VGG16 base, set up dir structure and init DataGen\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "\t\t\t\t  include_top=False,\n",
        "\t\t\t\t  input_shape=(150, 150, 3))\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luWiGXLn2tz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns VGG16 feature vectores and labels for sample_count images in directory\n",
        "def extract_features(directory, sample_count):\n",
        "\tfeatures = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "\tlabels = np.zeros(shape=(sample_count))\n",
        "\tgenerator = datagen.flow_from_directory(\n",
        "\t\tdirectory,\n",
        "\t\ttarget_size=(150, 150),\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tclass_mode='binary')\n",
        "\ti = 0\n",
        "\tfor input_batch, labels_batch in generator:\n",
        "\t\tfeatures_batch = conv_base.predict(input_batch)\n",
        "\t\tfeatures[i * batch_size : (i+1) * batch_size] = features_batch\n",
        "\t\tlabels[i * batch_size : (i+1) * batch_size] = labels_batch\n",
        "\t\ti += 1\n",
        "\t\tif i * batch_size >= sample_count:\n",
        "\t\t\tbreak\n",
        "\treturn features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN6NpTp33KSv",
        "colab_type": "code",
        "outputId": "f5cfe638-8086-48e6-8068-eb345edff135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Obtain and flatten feature+labels for train/validation/test\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "test_features, test_labels = extract_features(test_dir, 1000)\n",
        "\n",
        "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
        "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
        "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_-vcO8U4jnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build and compile the model with feature vectors as input\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "\tloss='binary_crossentropy',\n",
        "\tmetrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3K8vMim4vy7",
        "colab_type": "code",
        "outputId": "e8af4046-b9b3-4b9a-87de-a3122ff21ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1115
        }
      },
      "source": [
        "# Train and evaluate the model\n",
        "history = model.fit(train_features, train_labels,\n",
        "\tepochs=30,\n",
        "\tbatch_size=20,\n",
        "\tvalidation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.5741 - acc: 0.6875 - val_loss: 0.4269 - val_acc: 0.8300\n",
            "Epoch 2/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.4134 - acc: 0.8260 - val_loss: 0.3522 - val_acc: 0.8730\n",
            "Epoch 3/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.3529 - acc: 0.8475 - val_loss: 0.3150 - val_acc: 0.8830\n",
            "Epoch 4/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.3145 - acc: 0.8670 - val_loss: 0.2931 - val_acc: 0.8870\n",
            "Epoch 5/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.2886 - acc: 0.8840 - val_loss: 0.2797 - val_acc: 0.8900\n",
            "Epoch 6/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.2603 - acc: 0.8930 - val_loss: 0.2768 - val_acc: 0.8930\n",
            "Epoch 7/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.2439 - acc: 0.9065 - val_loss: 0.2730 - val_acc: 0.8950\n",
            "Epoch 8/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.2366 - acc: 0.9000 - val_loss: 0.2556 - val_acc: 0.8970\n",
            "Epoch 9/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.2169 - acc: 0.9140 - val_loss: 0.2507 - val_acc: 0.8990\n",
            "Epoch 10/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.2034 - acc: 0.9230 - val_loss: 0.2527 - val_acc: 0.8950\n",
            "Epoch 11/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1972 - acc: 0.9270 - val_loss: 0.2451 - val_acc: 0.9000\n",
            "Epoch 12/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1827 - acc: 0.9295 - val_loss: 0.2678 - val_acc: 0.8920\n",
            "Epoch 13/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1787 - acc: 0.9355 - val_loss: 0.2437 - val_acc: 0.9000\n",
            "Epoch 14/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1699 - acc: 0.9420 - val_loss: 0.2463 - val_acc: 0.8980\n",
            "Epoch 15/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1696 - acc: 0.9425 - val_loss: 0.2365 - val_acc: 0.9000\n",
            "Epoch 16/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1598 - acc: 0.9490 - val_loss: 0.2352 - val_acc: 0.9040\n",
            "Epoch 17/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1481 - acc: 0.9435 - val_loss: 0.2384 - val_acc: 0.9060\n",
            "Epoch 18/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1399 - acc: 0.9540 - val_loss: 0.2435 - val_acc: 0.9020\n",
            "Epoch 19/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1348 - acc: 0.9515 - val_loss: 0.2418 - val_acc: 0.9040\n",
            "Epoch 20/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1343 - acc: 0.9505 - val_loss: 0.2394 - val_acc: 0.9050\n",
            "Epoch 21/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1266 - acc: 0.9575 - val_loss: 0.2359 - val_acc: 0.9000\n",
            "Epoch 22/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1202 - acc: 0.9640 - val_loss: 0.2345 - val_acc: 0.9010\n",
            "Epoch 23/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1211 - acc: 0.9595 - val_loss: 0.2489 - val_acc: 0.9000\n",
            "Epoch 24/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1119 - acc: 0.9635 - val_loss: 0.2417 - val_acc: 0.9040\n",
            "Epoch 25/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1093 - acc: 0.9650 - val_loss: 0.2443 - val_acc: 0.9020\n",
            "Epoch 26/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.0993 - acc: 0.9705 - val_loss: 0.2410 - val_acc: 0.9020\n",
            "Epoch 27/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.1020 - acc: 0.9640 - val_loss: 0.2426 - val_acc: 0.9020\n",
            "Epoch 28/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.0927 - acc: 0.9725 - val_loss: 0.2388 - val_acc: 0.9030\n",
            "Epoch 29/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.0909 - acc: 0.9735 - val_loss: 0.2402 - val_acc: 0.9010\n",
            "Epoch 30/30\n",
            "2000/2000 [==============================] - 3s 1ms/sample - loss: 0.0886 - acc: 0.9735 - val_loss: 0.2479 - val_acc: 0.9020\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}