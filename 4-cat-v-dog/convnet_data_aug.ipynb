{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic-convnet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9aagEfYlCkXZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download and unzip the complete dogs-vs-cats dataset\n",
        "\n",
        "%env DIR=cats_and_dogs\n",
        "\n",
        "! curl -o dogs-vs-cats.zip https://storage.googleapis.com/peddy-ai-dl-data/deeplearning-repo/dogs-vs-cats.zip\n",
        "\n",
        "! unzip -o dogs-vs-cats.zip -d $DIR\n",
        "! mkdir $DIR/original_data\n",
        "! unzip -o $DIR/test1.zip -d $DIR/original_data\n",
        "! unzip -o $DIR/train.zip -d $DIR/original_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOF9hd4sYBw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create train/validation/test datasets from original data\n",
        "import os, shutil\n",
        "\n",
        "USE_DATA_AUGMENTATION = True\n",
        "\n",
        "base_dir = os.path.join(os.getcwd(), 'cats_and_dogs')\n",
        "original_dataset_dir = os.path.join(base_dir, 'original_data', 'train')\n",
        "\n",
        "data_segment_names = ['train', 'validation', 'test']\n",
        "labels = ['cat', 'dog']\n",
        "\n",
        "data_segments = {\n",
        "\tdata_segment_names[0]: (0, 1000),\n",
        "\tdata_segment_names[1]: (1000, 1500),\n",
        "\tdata_segment_names[2]: (1500, 2000)\n",
        "}\n",
        "\n",
        "def mkdir(dir):\n",
        "\ttry:\n",
        "\t\tos.mkdir(dir)\n",
        "\texcept OSError:\n",
        "\t\tprint('{} not created - alread exists'.format(dir), dir)\n",
        "\n",
        "def prepare_data():\n",
        "\t# Make data segments directories\n",
        "\tfor segment in data_segment_names:\n",
        "\t\tsegment_dir = os.path.join(base_dir, segment)\n",
        "\t\tmkdir(segment_dir)\n",
        "\t\t# Make label directories for each data segment\n",
        "\t\tfor label in labels:\n",
        "\t\t\tlabel_segment_dir = os.path.join(segment_dir, label + 's')\n",
        "\t\t\tmkdir(label_segment_dir)\n",
        "\t\t\t# Copy data over for each data segment-label pair\n",
        "\t\t\tfnames = [(label+'.{}.jpg').format(i) for i in range(data_segments[segment][0], data_segments[segment][1])]\n",
        "\t\t\tfor fname in fnames:\n",
        "\t\t\t\tsrc = os.path.join(original_dataset_dir, fname)\n",
        "\t\t\t\tdst = os.path.join(label_segment_dir, fname)\n",
        "\t\t\t\tshutil.copyfile(src, dst)\n",
        "\n",
        "prepare_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6TnlhUDc0W5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install tf-nightly-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMeIJ8qag4uw",
        "colab_type": "code",
        "outputId": "f4a9b4d0-c87d-47c6-ef7e-3f138881012f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TDMzpmqkg-IA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build a network with 4 convolution-maxpooling blocks\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "\t\t\t  loss='binary_crossentropy',\n",
        "\t\t\t  metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pzLLPWY_yQFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "27c655ec-5747-450e-c794-8db30b2d5ac1"
      },
      "cell_type": "code",
      "source": [
        "# Create data generators for training and validation\n",
        "train_dir = os.path.join(os.getcwd(), 'cats_and_dogs', 'train')\n",
        "validation_dir = os.path.join(os.getcwd(), 'cats_and_dogs', 'validation')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "if (USE_DATA_AUGMENTATION):\n",
        "  print(\"Using data augmentation\")\n",
        "  train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_dir,\n",
        "\ttarget_size=(150, 150),\n",
        "\tbatch_size=20,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_dir,\n",
        "\ttarget_size=(150, 150),\n",
        "\tbatch_size=20,\n",
        "\tclass_mode='binary')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using data augmentation\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LSXUOhHOyNew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "c3a0d187-119c-4ef0-be65-c263a5702355"
      },
      "cell_type": "code",
      "source": [
        "# Train the model using training and validation generators\n",
        "history = model.fit_generator(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=100,\n",
        "\tepochs=10,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.6868 - acc: 0.5490 - val_loss: 0.7005 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.6695 - acc: 0.5835 - val_loss: 0.6828 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.6523 - acc: 0.6045 - val_loss: 0.6846 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.6298 - acc: 0.6470 - val_loss: 0.5191 - val_acc: 0.7500\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.6185 - acc: 0.6580 - val_loss: 0.5219 - val_acc: 0.8000\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.5990 - acc: 0.6735 - val_loss: 0.5134 - val_acc: 0.8000\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.6019 - acc: 0.6830 - val_loss: 0.4439 - val_acc: 0.8500\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.5954 - acc: 0.6780 - val_loss: 0.5297 - val_acc: 0.7500\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 131s 1s/step - loss: 0.5938 - acc: 0.6785 - val_loss: 0.4159 - val_acc: 0.9000\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.5824 - acc: 0.6775 - val_loss: 0.4463 - val_acc: 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qJxISC2rk3z8",
        "colab_type": "code",
        "outputId": "aefaa903-9321-4fab-f6b0-19372445ab6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "test_dir = os.path.join(os.getcwd(), 'cats_and_dogs', 'test')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "  test_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=20,\n",
        "  class_mode='binary')\n",
        "\n",
        "loss, accuracy = model.evaluate_generator(test_generator)\n",
        "print(accuracy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "0.695\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}